{"cells":[{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nfrom torch import nn, optim\nfrom sklearn.preprocessing import MinMaxScaler\n\n# function for data process\ndef createSeqLab(trainData, windowSz):\n    # trainData = normalized tensor\n    # ret = set of (seq, label)\n    ret = []\n    dataSz = len(trainData)\n    for i in range(dataSz - windowSz):\n        seq = trainData[i : i+windowSz]\n        label = trainData[i+windowSz]\n        ret.append((seq, label))\n    return ret\n\n# RNN (LSTM) model\nclass MyModel(nn.Module):\n    def __init__(self, inputSz, hiddenSz, batchSz, outputSz, layerSz):\n        super(MyModel, self).__init__()\n        self.inputSz = inputSz\n        self.hiddenSz = hiddenSz\n        self.batchSz = batchSz\n        self.outputSz = outputSz\n        self.layerSz = layerSz\n        self.lstm = nn.LSTM(inputSz, hiddenSz, layerSz)\n        self.linear = nn.Linear(hiddenSz, outputSz)\n        \n    def reset_hidden_state(self):\n        self.hidden = (\n            torch.zeros(self.layerSz, self.batchSz, self.hiddenSz),\n            torch.zeros(self.layerSz, self.batchSz, self.hiddenSz))\n    \n    def forward(self, seq):\n        lstm_out, self.hidden = self.lstm(seq.view(len(seq), self.batchSz, -1), self.hidden)\n        lastStep = lstm_out.view(self.batchSz, len(seq), self.hiddenSz)[-1]\n        pred = self.linear(lastStep)\n        return pred[-1]\n\n    \n# Read the train/test file from kaggle\ntrain = pd.read_csv('../input/yaifinal/train_covid.csv')\ntest = pd.read_csv('../input/yaifinal/test_covid.csv')\n# only consider 3 attributes for train file (no missing value)\ntrain = train[['location', 'new_cases', 'new_deaths']]\n# make test file to submission format\ntest = test[['id', 'location']]\ntest['new_cases'] = 0\ntest['new_deaths'] = 0\ncounter = 0\n\n# hyper parameters\nwindowSz = 7 # consider (windowSz) days to predict next day\nhiddenSz = 64\nlayerSz = 2\nnumEpoch = 25\nalpha = 0.0005 # learning rate\n\n\n\ntrainSt, testSt = 0, 0\nwhile trainSt < len(train) and testSt < len(test):\n    # split data by locaiton\n    country = train.loc[trainSt, 'location']\n    if country != test.loc[testSt, 'location']:\n        print(\"This train data sucks\")\n        break\n    \n    trainEd, testEd = trainSt, testSt\n    while trainEd < len(train) and train.loc[trainEd, 'location'] == country:\n        trainEd += 1\n    while testEd < len(test) and test.loc[testEd, 'location'] == country:\n        testEd += 1\n\n    trainData = train.loc[trainSt:trainEd-1, ['new_cases', 'new_deaths']].to_numpy()\n    # data normalize\n    scaler = MinMaxScaler(feature_range=(-1, 1))\n    trainData = scaler.fit_transform(trainData)\n    # convert data set into tensor\n    trainData = torch.FloatTensor(trainData)\n    trainSeqLab = createSeqLab(trainData, windowSz)\n\n    # create LSTM model and train it using trainSeqLab data\n    model = MyModel(2, hiddenSz, 1, 2, layerSz)\n    optimizer = optim.Adam(model.parameters(), lr=alpha)\n    lossFunc = nn.MSELoss()\n    \n    for i in range(numEpoch):\n        for item in trainSeqLab:\n            seq, label = item\n            model.reset_hidden_state()\n            optimizer.zero_grad()  \n            pred = model(seq)\n            loss = lossFunc(pred, label)\n            loss.backward()\n            optimizer.step()\n\n    # using trained LSTM model, predict next few days\n    wantPred = testEd - testSt\n    trainSt, testSt = trainEd, testEd\n    predList = trainData.tolist()\n    model.eval()\n    \n    # append predicted values to predList\n    for i in range(wantPred):\n        seq = torch.FloatTensor(predList[-windowSz:])\n        model.reset_hidden_state()\n        pred = model(seq)\n        predList.append(pred.tolist())\n        \n    predList = predList[-wantPred:]\n    # convert to actual predicted value\n    predList = scaler.inverse_transform(np.array(predList))\n    # write result\n    for i in range(wantPred):\n        predCase = max(0, round(predList[i, 0]))\n        predDeath = max(0, round(predList[i, 1]))\n        test.loc[counter, 'new_cases'] = predCase\n        test.loc[counter, 'new_deaths'] = predDeath\n        counter += 1\n        \n    print(\"Processing:\", str(counter) + '/' + str(len(test)))\n\n# make submission format\ndel test['location']\n# save file\ntest.to_csv(\"Submit.csv\", index=False)","execution_count":1,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"invalid syntax (<ipython-input-1-5bf2c3849ed4>, line 118)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-5bf2c3849ed4>\"\u001b[0;36m, line \u001b[0;32m118\u001b[0m\n\u001b[0;31m    int predCase = max(0, round(predList[i, 0]))\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]}],"metadata":{"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat":4,"nbformat_minor":4}